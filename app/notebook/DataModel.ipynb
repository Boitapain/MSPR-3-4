{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f8a0879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Incohérence pour 'Algeria' au mois de 2020-03-01 00:00:00 [Recovered]: 46 ≠ 0 + 200 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Benin' au mois de 2020-05-01 00:00:00 [Confirmed]: 232 ≠ 64 + 377 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'China' au mois de 2020-04-01 00:00:00 [Recovered]: 76951 ≠ 74645 + 4006 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Cote d'Ivoire' au mois de 2020-06-01 00:00:00 [Recovered]: 4273 ≠ 1435 + 3460 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Ecuador' au mois de 2020-05-01 00:00:00 [Confirmed]: 39098 ≠ 24934 + 17277 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Finland' au mois de 2020-05-01 00:00:00 [Recovered]: 5500 ≠ 3000 + 2900 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'France' au mois de 2020-04-01 00:00:00 [Confirmed]: 167299 ≠ 52827 + 119170 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'France' au mois de 2020-05-01 00:00:00 [Deaths]: 28805 ≠ 24379 + 4860 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'France' au mois de 2020-05-01 00:00:00 [Confirmed]: 189009 ≠ 167299 + 22095 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'France' au mois de 2020-06-01 00:00:00 [Confirmed]: 202063 ≠ 189009 + 14539 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Italy' au mois de 2020-06-01 00:00:00 [Confirmed]: 240578 ≠ 232997 + 7729 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Jordan' au mois de 2020-05-01 00:00:00 [Recovered]: 522 ≠ 362 + 338 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Jordan' au mois de 2020-07-01 00:00:00 [Confirmed]: 1176 ≠ 1132 + 154 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Kazakhstan' au mois de 2020-07-01 00:00:00 [Recovered]: 54404 ≠ 13558 + 46120 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Lithuania' au mois de 2020-04-01 00:00:00 [Confirmed]: 1385 ≠ 537 + 953 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Mexico' au mois de 2020-07-01 00:00:00 [Recovered]: 303810 ≠ 174538 + 161868 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Peru' au mois de 2020-06-01 00:00:00 [Recovered]: 174535 ≠ 67208 + 110155 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Portugal' au mois de 2020-05-01 00:00:00 [Confirmed]: 32500 ≠ 25045 + 7616 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Serbia' au mois de 2020-06-01 00:00:00 [Recovered]: 12662 ≠ 6698 + 6282 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Serbia' au mois de 2020-07-01 00:00:00 [Recovered]: 0 ≠ 12662 + 18466 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Spain' au mois de 2020-04-01 00:00:00 [Confirmed]: 213435 ≠ 95923 + 127546 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Spain' au mois de 2020-05-01 00:00:00 [Deaths]: 27127 ≠ 24543 + 6420 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Spain' au mois de 2020-05-01 00:00:00 [Confirmed]: 239479 ≠ 213435 + 26416 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Tajikistan' au mois de 2020-05-01 00:00:00 [Recovered]: 2004 ≠ 0 + 2346 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'US' au mois de 2020-05-01 00:00:00 [Recovered]: 444758 ≠ 153947 + 295703 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Uganda' au mois de 2020-05-01 00:00:00 [Confirmed]: 417 ≠ 83 + 438 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Uganda' au mois de 2020-07-01 00:00:00 [Recovered]: 986 ≠ 819 + 393 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'United Kingdom' au mois de 2020-04-01 00:00:00 [Recovered]: 859 ≠ 179 + 1324 (tolérance ±100)\n",
      "\n",
      "ETL terminé. Fichier sauvegardé sous : data_etl_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"full_grouped.csv\")  \n",
    "\n",
    "# Renommer les colonnes pour simplifier\n",
    "df = df.rename(columns={\n",
    "    'Date': 'Date',\n",
    "    'Country/Region': 'Country',\n",
    "    'Confirmed': 'Confirmed',\n",
    "    'Deaths': 'Deaths',\n",
    "    'Recovered': 'Recovered',\n",
    "    'New cases': 'New cases',\n",
    "    'New deaths': 'New deaths',\n",
    "    'New recovered': 'New recovered'\n",
    "})\n",
    "\n",
    "# Convertir la date et créer une colonne mois\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# Garder uniquement les colonnes nécessaires\n",
    "df = df[['Month', 'Country', 'Confirmed', 'Deaths', 'Recovered',\n",
    "         'New cases', 'New deaths', 'New recovered']]\n",
    "\n",
    "# Convertir les colonnes temporelles en valeurs absolues\n",
    "for col in ['New cases', 'New deaths', 'New recovered']:\n",
    "    df[col] = df[col].abs()\n",
    "\n",
    "# Grouper par mois et pays\n",
    "df_grouped = df.groupby(['Month', 'Country'], as_index=False).agg({\n",
    "    'Confirmed': 'last',\n",
    "    'Deaths': 'last',\n",
    "    'Recovered': 'last',\n",
    "    'New cases': 'sum',\n",
    "    'New deaths': 'sum',\n",
    "    'New recovered': 'sum'\n",
    "})\n",
    "\n",
    "# Ajouter une colonne Id auto-incrémentée\n",
    "df_grouped.insert(0, 'Id', range(1, len(df_grouped) + 1))\n",
    "\n",
    "# Ajouter une colonne 'nom' avec la valeur 'COVID-19' au début du DataFrame\n",
    "df_grouped.insert(1, 'Name', 'COVID-19')\n",
    "\n",
    "# Vérifier la cohérence des données\n",
    "if df.isnull().any().any():\n",
    "    print(\"Les données contiennent des valeurs nulles. Vérifiez le fichier source.\")\n",
    "\n",
    "# Vérifier que les colonnes numériques ne contiennent pas de valeurs négatives\n",
    "for col in ['Confirmed', 'Deaths', 'Recovered', 'New cases', 'New deaths', 'New recovered']:\n",
    "    if (df[col] < 0).any():\n",
    "        print(f\"La colonne '{col}' contient des valeurs négatives.\")\n",
    "\n",
    "# Vérifier que les colonnes nécessaires sont présentes\n",
    "required_columns = ['Month', 'Country', 'Confirmed', 'Deaths', 'Recovered', 'New cases', 'New deaths', 'New recovered']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        print(f\"La colonne requise '{col}' est manquante dans les données.\")\n",
    "\n",
    "MARGIN = 100  # Tolérance pour les incohérences\n",
    "# Vérification des incohérences\n",
    "# Initialiser une liste pour stocker les incohérences\n",
    "inconsistencies = []\n",
    "\n",
    "# Vérification des incohérences dans les données\n",
    "# Parcourir chaque pays et vérifier les incohérences\n",
    "for country, group in df_grouped.groupby('Country'):\n",
    "    group = group.sort_values('Month').reset_index(drop=True)\n",
    "\n",
    "\n",
    "    for i in range(1, len(group)):\n",
    "        current = group.iloc[i]\n",
    "        prev = group.iloc[i - 1]\n",
    "\n",
    "        # Vérification décès\n",
    "        expected_deaths = prev['Deaths'] + current['New deaths']\n",
    "        if abs(current['Deaths'] - expected_deaths) > MARGIN:\n",
    "            print(f\"⚠️ Incohérence pour '{country}' au mois de {current['Month']} [Deaths]: \"\n",
    "                  f\"{current['Deaths']} ≠ {prev['Deaths']} + {current['New deaths']} (tolérance ±{MARGIN})\")\n",
    "            inconsistencies.append({\n",
    "                'Country': country,\n",
    "                'Month': current['Month'],\n",
    "                'Field': 'Deaths',\n",
    "                'Actual': current['Deaths'],\n",
    "                'Expected': expected_deaths\n",
    "            })\n",
    "\n",
    "        # Vérification cas confirmés\n",
    "        expected_confirmed = prev['Confirmed'] + current['New cases']\n",
    "        if abs(current['Confirmed'] - expected_confirmed) > MARGIN:\n",
    "            print(f\"⚠️ Incohérence pour '{country}' au mois de {current['Month']} [Confirmed]: \"\n",
    "                  f\"{current['Confirmed']} ≠ {prev['Confirmed']} + {current['New cases']} (tolérance ±{MARGIN})\")\n",
    "            inconsistencies.append({\n",
    "                'Country': country,\n",
    "                'Month': current['Month'],\n",
    "                'Field': 'Confirmed',\n",
    "                'Actual': current['Confirmed'],\n",
    "                'Expected': expected_confirmed\n",
    "            })\n",
    "\n",
    "        # Vérification récupérations\n",
    "        expected_recovered = prev['Recovered'] + current['New recovered']\n",
    "        if abs(current['Recovered'] - expected_recovered) > MARGIN:\n",
    "            print(f\"⚠️ Incohérence pour '{country}' au mois de {current['Month']} [Recovered]: \"\n",
    "                  f\"{current['Recovered']} ≠ {prev['Recovered']} + {current['New recovered']} (tolérance ±{MARGIN})\")\n",
    "            inconsistencies.append({\n",
    "                'Country': country,\n",
    "                'Month': current['Month'],\n",
    "                'Field': 'Recovered',\n",
    "                'Actual': current['Recovered'],\n",
    "                'Expected': expected_recovered\n",
    "            })\n",
    "\n",
    "\n",
    "inconsistencies_df = pd.DataFrame(inconsistencies)\n",
    "inconsistencies_df.head()\n",
    "\n",
    "# Sauvegarder le résultat dans le répertoire courant\n",
    "df_grouped.to_csv(\"data_etl_output.csv\", index=False)\n",
    "\n",
    "print(\"\\nETL terminé. Fichier sauvegardé sous : data_etl_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9548065c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ComplexWarning' from 'numpy.core.numeric' (c:\\Users\\hugod\\OneDrive\\Bureau\\Mspr2\\MSPR-3-4\\.venv\\lib\\site-packages\\numpy\\core\\numeric.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugod\\OneDrive\\Bureau\\Mspr2\\MSPR-3-4\\.venv\\lib\\site-packages\\sklearn\\__init__.py:83\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\hugod\\OneDrive\\Bureau\\Mspr2\\MSPR-3-4\\.venv\\lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[1;32mc:\\Users\\hugod\\OneDrive\\Bureau\\Mspr2\\MSPR-3-4\\.venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "File \u001b[1;32mc:\\Users\\hugod\\OneDrive\\Bureau\\Mspr2\\MSPR-3-4\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugod\\OneDrive\\Bureau\\Mspr2\\MSPR-3-4\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# mypy error: Module 'numpy.core.numeric' has no attribute 'ComplexWarning'\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumeric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ComplexWarning' from 'numpy.core.numeric' (c:\\Users\\hugod\\OneDrive\\Bureau\\Mspr2\\MSPR-3-4\\.venv\\lib\\site-packages\\numpy\\core\\numeric.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"data_etl_output.csv\")\n",
    "\n",
    "# Créer des colonnes décalées pour les prédictions\n",
    "for col in ['Confirmed', 'Deaths', 'Recovered']:\n",
    "    df[f'{col}_lag1'] = df.groupby('Country')[col].shift(1)\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes dues au décalage\n",
    "df = df.dropna()\n",
    "\n",
    "# Encoder les pays\n",
    "le = LabelEncoder()\n",
    "df['Country_encoded'] = le.fit_transform(df['Country'])\n",
    "\n",
    "# Définir les features et la target\n",
    "features = ['Confirmed_lag1', 'Deaths_lag1', 'Recovered_lag1', 'Country_encoded']\n",
    "targets = ['Confirmed', 'Deaths', 'Recovered']\n",
    "\n",
    "X = df[features]\n",
    "y = df[targets]\n",
    "\n",
    "#load the dataset \n",
    "\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor RMSE:\n",
      "Confirmed: 56527.16753956689, Deaths: 3834.3655447739757, Recovered: 24347.824072305015\n",
      "Gradient Boosting Regressor RMSE:\n",
      "Confirmed: 80006.05882751447, Deaths: 2279.5740766256695, Recovered: 30815.436802704888\n",
      "Linear Regression RMSE:\n",
      "Confirmed: 55424.770449724325, Deaths: 2546.7357102811775, Recovered: 41015.71417962562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "rfr_model = RandomForestRegressor(random_state=42)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "\n",
    "rfr_rmse_confirmed = np.sqrt(mean_squared_error(y_test['Confirmed'], rfr_model.predict(X_test)[:, 0]))\n",
    "rfr_rmse_deaths = np.sqrt(mean_squared_error(y_test['Deaths'], rfr_model.predict(X_test)[:, 1]))\n",
    "rfr_rmse_recovered = np.sqrt(mean_squared_error(y_test['Recovered'], rfr_model.predict(X_test)[:, 2]))\n",
    "\n",
    "print(\"Random Forest Regressor RMSE:\")\n",
    "print(f\"Confirmed: {rfr_rmse_confirmed}, Deaths: {rfr_rmse_deaths}, Recovered: {rfr_rmse_recovered}\")\n",
    "\n",
    "# Gradient Boosting Regressor with MultiOutputRegressor\n",
    "gbr_model = MultiOutputRegressor(GradientBoostingRegressor(random_state=42))\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions with Gradient Boosting\n",
    "gbr_y_pred = gbr_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for Gradient Boosting\n",
    "gbr_rmse_confirmed = np.sqrt(mean_squared_error(y_test['Confirmed'], gbr_y_pred[:, 0]))\n",
    "gbr_rmse_deaths = np.sqrt(mean_squared_error(y_test['Deaths'], gbr_y_pred[:, 1]))\n",
    "gbr_rmse_recovered = np.sqrt(mean_squared_error(y_test['Recovered'], gbr_y_pred[:, 2]))\n",
    "\n",
    "print(\"Gradient Boosting Regressor RMSE:\")\n",
    "print(f\"Confirmed: {gbr_rmse_confirmed}, Deaths: {gbr_rmse_deaths}, Recovered: {gbr_rmse_recovered}\")\n",
    "\n",
    "# Linear Regression with MultiOutputRegressor\n",
    "lr_model = MultiOutputRegressor(LinearRegression())\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions with Linear Regression\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for Linear Regression\n",
    "lr_rmse_confirmed = np.sqrt(mean_squared_error(y_test['Confirmed'], lr_y_pred[:, 0]))\n",
    "lr_rmse_deaths = np.sqrt(mean_squared_error(y_test['Deaths'], lr_y_pred[:, 1]))\n",
    "lr_rmse_recovered = np.sqrt(mean_squared_error(y_test['Recovered'], lr_y_pred[:, 2]))\n",
    "\n",
    "print(\"Linear Regression RMSE:\")\n",
    "print(f\"Confirmed: {lr_rmse_confirmed}, Deaths: {lr_rmse_deaths}, Recovered: {lr_rmse_recovered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8a66723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le pickle pour le modèle Random Forest\n",
    "import pickle\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(rfr_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
