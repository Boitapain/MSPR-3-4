{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f8a0879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Incohérence pour 'Algeria' au mois de 2020-03-01 00:00:00 [Recovered]: 46 ≠ 0 + 200 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Benin' au mois de 2020-05-01 00:00:00 [Confirmed]: 232 ≠ 64 + 377 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'China' au mois de 2020-04-01 00:00:00 [Recovered]: 76951 ≠ 74645 + 4006 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Cote d'Ivoire' au mois de 2020-06-01 00:00:00 [Recovered]: 4273 ≠ 1435 + 3460 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Ecuador' au mois de 2020-05-01 00:00:00 [Confirmed]: 39098 ≠ 24934 + 17277 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Finland' au mois de 2020-05-01 00:00:00 [Recovered]: 5500 ≠ 3000 + 2900 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'France' au mois de 2020-04-01 00:00:00 [Confirmed]: 167299 ≠ 52827 + 119170 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'France' au mois de 2020-05-01 00:00:00 [Deaths]: 28805 ≠ 24379 + 4860 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'France' au mois de 2020-05-01 00:00:00 [Confirmed]: 189009 ≠ 167299 + 22095 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'France' au mois de 2020-06-01 00:00:00 [Confirmed]: 202063 ≠ 189009 + 14539 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Italy' au mois de 2020-06-01 00:00:00 [Confirmed]: 240578 ≠ 232997 + 7729 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Jordan' au mois de 2020-05-01 00:00:00 [Recovered]: 522 ≠ 362 + 338 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Jordan' au mois de 2020-07-01 00:00:00 [Confirmed]: 1176 ≠ 1132 + 154 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Kazakhstan' au mois de 2020-07-01 00:00:00 [Recovered]: 54404 ≠ 13558 + 46120 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Lithuania' au mois de 2020-04-01 00:00:00 [Confirmed]: 1385 ≠ 537 + 953 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Mexico' au mois de 2020-07-01 00:00:00 [Recovered]: 303810 ≠ 174538 + 161868 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Peru' au mois de 2020-06-01 00:00:00 [Recovered]: 174535 ≠ 67208 + 110155 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Portugal' au mois de 2020-05-01 00:00:00 [Confirmed]: 32500 ≠ 25045 + 7616 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Serbia' au mois de 2020-06-01 00:00:00 [Recovered]: 12662 ≠ 6698 + 6282 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Serbia' au mois de 2020-07-01 00:00:00 [Recovered]: 0 ≠ 12662 + 18466 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Spain' au mois de 2020-04-01 00:00:00 [Confirmed]: 213435 ≠ 95923 + 127546 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Spain' au mois de 2020-05-01 00:00:00 [Deaths]: 27127 ≠ 24543 + 6420 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Spain' au mois de 2020-05-01 00:00:00 [Confirmed]: 239479 ≠ 213435 + 26416 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Tajikistan' au mois de 2020-05-01 00:00:00 [Recovered]: 2004 ≠ 0 + 2346 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'US' au mois de 2020-05-01 00:00:00 [Recovered]: 444758 ≠ 153947 + 295703 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Uganda' au mois de 2020-05-01 00:00:00 [Confirmed]: 417 ≠ 83 + 438 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'Uganda' au mois de 2020-07-01 00:00:00 [Recovered]: 986 ≠ 819 + 393 (tolérance ±100)\n",
      "⚠️ Incohérence pour 'United Kingdom' au mois de 2020-04-01 00:00:00 [Recovered]: 859 ≠ 179 + 1324 (tolérance ±100)\n",
      "\n",
      "ETL terminé. Fichier sauvegardé sous : data_etl_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"full_grouped.csv\")  \n",
    "\n",
    "# Renommer les colonnes pour simplifier\n",
    "df = df.rename(columns={\n",
    "    'Date': 'Date',\n",
    "    'Country/Region': 'Country',\n",
    "    'Confirmed': 'Confirmed',\n",
    "    'Deaths': 'Deaths',\n",
    "    'Recovered': 'Recovered',\n",
    "    'New cases': 'New cases',\n",
    "    'New deaths': 'New deaths',\n",
    "    'New recovered': 'New recovered'\n",
    "})\n",
    "\n",
    "# Convertir la date et créer une colonne mois\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# Garder uniquement les colonnes nécessaires\n",
    "df = df[['Month', 'Country', 'Confirmed', 'Deaths', 'Recovered',\n",
    "         'New cases', 'New deaths', 'New recovered']]\n",
    "\n",
    "# Convertir les colonnes temporelles en valeurs absolues\n",
    "for col in ['New cases', 'New deaths', 'New recovered']:\n",
    "    df[col] = df[col].abs()\n",
    "\n",
    "# Grouper par mois et pays\n",
    "df_grouped = df.groupby(['Month', 'Country'], as_index=False).agg({\n",
    "    'Confirmed': 'last',\n",
    "    'Deaths': 'last',\n",
    "    'Recovered': 'last',\n",
    "    'New cases': 'sum',\n",
    "    'New deaths': 'sum',\n",
    "    'New recovered': 'sum'\n",
    "})\n",
    "\n",
    "# Ajouter une colonne Id auto-incrémentée\n",
    "df_grouped.insert(0, 'Id', range(1, len(df_grouped) + 1))\n",
    "\n",
    "# Ajouter une colonne 'nom' avec la valeur 'COVID-19' au début du DataFrame\n",
    "df_grouped.insert(1, 'Name', 'COVID-19')\n",
    "\n",
    "# Vérifier la cohérence des données\n",
    "if df.isnull().any().any():\n",
    "    print(\"Les données contiennent des valeurs nulles. Vérifiez le fichier source.\")\n",
    "\n",
    "# Vérifier que les colonnes numériques ne contiennent pas de valeurs négatives\n",
    "for col in ['Confirmed', 'Deaths', 'Recovered', 'New cases', 'New deaths', 'New recovered']:\n",
    "    if (df[col] < 0).any():\n",
    "        print(f\"La colonne '{col}' contient des valeurs négatives.\")\n",
    "\n",
    "# Vérifier que les colonnes nécessaires sont présentes\n",
    "required_columns = ['Month', 'Country', 'Confirmed', 'Deaths', 'Recovered', 'New cases', 'New deaths', 'New recovered']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        print(f\"La colonne requise '{col}' est manquante dans les données.\")\n",
    "\n",
    "MARGIN = 100  # Tolérance pour les incohérences\n",
    "# Vérification des incohérences\n",
    "# Initialiser une liste pour stocker les incohérences\n",
    "inconsistencies = []\n",
    "\n",
    "# Vérification des incohérences dans les données\n",
    "# Parcourir chaque pays et vérifier les incohérences\n",
    "for country, group in df_grouped.groupby('Country'):\n",
    "    group = group.sort_values('Month').reset_index(drop=True)\n",
    "\n",
    "\n",
    "    for i in range(1, len(group)):\n",
    "        current = group.iloc[i]\n",
    "        prev = group.iloc[i - 1]\n",
    "\n",
    "        # Vérification décès\n",
    "        expected_deaths = prev['Deaths'] + current['New deaths']\n",
    "        if abs(current['Deaths'] - expected_deaths) > MARGIN:\n",
    "            print(f\"⚠️ Incohérence pour '{country}' au mois de {current['Month']} [Deaths]: \"\n",
    "                  f\"{current['Deaths']} ≠ {prev['Deaths']} + {current['New deaths']} (tolérance ±{MARGIN})\")\n",
    "            inconsistencies.append({\n",
    "                'Country': country,\n",
    "                'Month': current['Month'],\n",
    "                'Field': 'Deaths',\n",
    "                'Actual': current['Deaths'],\n",
    "                'Expected': expected_deaths\n",
    "            })\n",
    "\n",
    "        # Vérification cas confirmés\n",
    "        expected_confirmed = prev['Confirmed'] + current['New cases']\n",
    "        if abs(current['Confirmed'] - expected_confirmed) > MARGIN:\n",
    "            print(f\"⚠️ Incohérence pour '{country}' au mois de {current['Month']} [Confirmed]: \"\n",
    "                  f\"{current['Confirmed']} ≠ {prev['Confirmed']} + {current['New cases']} (tolérance ±{MARGIN})\")\n",
    "            inconsistencies.append({\n",
    "                'Country': country,\n",
    "                'Month': current['Month'],\n",
    "                'Field': 'Confirmed',\n",
    "                'Actual': current['Confirmed'],\n",
    "                'Expected': expected_confirmed\n",
    "            })\n",
    "\n",
    "        # Vérification récupérations\n",
    "        expected_recovered = prev['Recovered'] + current['New recovered']\n",
    "        if abs(current['Recovered'] - expected_recovered) > MARGIN:\n",
    "            print(f\"⚠️ Incohérence pour '{country}' au mois de {current['Month']} [Recovered]: \"\n",
    "                  f\"{current['Recovered']} ≠ {prev['Recovered']} + {current['New recovered']} (tolérance ±{MARGIN})\")\n",
    "            inconsistencies.append({\n",
    "                'Country': country,\n",
    "                'Month': current['Month'],\n",
    "                'Field': 'Recovered',\n",
    "                'Actual': current['Recovered'],\n",
    "                'Expected': expected_recovered\n",
    "            })\n",
    "\n",
    "\n",
    "inconsistencies_df = pd.DataFrame(inconsistencies)\n",
    "inconsistencies_df.head()\n",
    "\n",
    "# Sauvegarder le résultat dans le répertoire courant\n",
    "df_grouped.to_csv(\"data_etl_output.csv\", index=False)\n",
    "\n",
    "print(\"\\nETL terminé. Fichier sauvegardé sous : data_etl_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9548065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"data_etl_output.csv\")\n",
    "\n",
    "# Créer des colonnes décalées pour les prédictions\n",
    "for col in ['Confirmed', 'Deaths', 'Recovered']:\n",
    "    df[f'{col}_lag1'] = df.groupby('Country')[col].shift(1)\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes dues au décalage\n",
    "df = df.dropna()\n",
    "\n",
    "# Encoder les pays\n",
    "le = LabelEncoder()\n",
    "df['Country_encoded'] = le.fit_transform(df['Country'])\n",
    "\n",
    "# Définir les features et la target\n",
    "features = ['Confirmed_lag1', 'Deaths_lag1', 'Recovered_lag1', 'Country_encoded']\n",
    "targets = ['Confirmed', 'Deaths', 'Recovered']\n",
    "\n",
    "X = df[features]\n",
    "y = df[targets]\n",
    "\n",
    "#load the dataset \n",
    "\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f0ec33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor RMSE:\n",
      "Confirmed: 56527.16753956689, Deaths: 3834.3655447739757, Recovered: 24347.824072305015\n",
      "Gradient Boosting Regressor RMSE:\n",
      "Confirmed: 80006.05882751447, Deaths: 2279.5740766256695, Recovered: 30815.436802704888\n",
      "Linear Regression RMSE:\n",
      "Confirmed: 55424.77044972432, Deaths: 2546.735710281176, Recovered: 41015.71417962556\n",
      "\n",
      "RMSE scores:\n",
      "Random Forest Regressor R2:\n",
      "Confirmed: 0.8119107871463432, Deaths: 0.6582321397024737, Recovered: 0.9115087087356599\n",
      "Gradient Boosting Regressor R2:\n",
      "Confirmed: 0.6232136209458147, Deaths: 0.8792042619829725, Recovered: 0.8582520200233096\n",
      "Linear Regression R2:\n",
      "Confirmed: 0.8191755110616417, Deaths: 0.8492310367278773, Recovered: 0.748880303194476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "rfr_model = RandomForestRegressor(random_state=42)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "\n",
    "rfr_rmse_confirmed = np.sqrt(mean_squared_error(y_test['Confirmed'], rfr_model.predict(X_test)[:, 0]))\n",
    "rfr_rmse_deaths = np.sqrt(mean_squared_error(y_test['Deaths'], rfr_model.predict(X_test)[:, 1]))\n",
    "rfr_rmse_recovered = np.sqrt(mean_squared_error(y_test['Recovered'], rfr_model.predict(X_test)[:, 2]))\n",
    "\n",
    "print(\"Random Forest Regressor RMSE:\")\n",
    "print(f\"Confirmed: {rfr_rmse_confirmed}, Deaths: {rfr_rmse_deaths}, Recovered: {rfr_rmse_recovered}\")\n",
    "\n",
    "# Gradient Boosting Regressor with MultiOutputRegressor\n",
    "gbr_model = MultiOutputRegressor(GradientBoostingRegressor(random_state=42))\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions with Gradient Boosting\n",
    "gbr_y_pred = gbr_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for Gradient Boosting\n",
    "gbr_rmse_confirmed = np.sqrt(mean_squared_error(y_test['Confirmed'], gbr_y_pred[:, 0]))\n",
    "gbr_rmse_deaths = np.sqrt(mean_squared_error(y_test['Deaths'], gbr_y_pred[:, 1]))\n",
    "gbr_rmse_recovered = np.sqrt(mean_squared_error(y_test['Recovered'], gbr_y_pred[:, 2]))\n",
    "\n",
    "print(\"Gradient Boosting Regressor RMSE:\")\n",
    "print(f\"Confirmed: {gbr_rmse_confirmed}, Deaths: {gbr_rmse_deaths}, Recovered: {gbr_rmse_recovered}\")\n",
    "\n",
    "# Linear Regression with MultiOutputRegressor\n",
    "lr_model = MultiOutputRegressor(LinearRegression())\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions with Linear Regression\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for Linear Regression\n",
    "lr_rmse_confirmed = np.sqrt(mean_squared_error(y_test['Confirmed'], lr_y_pred[:, 0]))\n",
    "lr_rmse_deaths = np.sqrt(mean_squared_error(y_test['Deaths'], lr_y_pred[:, 1]))\n",
    "lr_rmse_recovered = np.sqrt(mean_squared_error(y_test['Recovered'], lr_y_pred[:, 2]))\n",
    "\n",
    "print(\"Linear Regression RMSE:\")\n",
    "print(f\"Confirmed: {lr_rmse_confirmed}, Deaths: {lr_rmse_deaths}, Recovered: {lr_rmse_recovered}\")\n",
    "\n",
    "print(\"\\nRMSE scores:\")\n",
    "# score r2 random forest\n",
    "from sklearn.metrics import r2_score\n",
    "rfr_r2_confirmed = r2_score(y_test['Confirmed'], rfr_model.predict(X_test)[:, 0])\n",
    "rfr_r2_deaths = r2_score(y_test['Deaths'], rfr_model.predict(X_test)[:, 1])\n",
    "rfr_r2_recovered = r2_score(y_test['Recovered'], rfr_model.predict(X_test)[:, 2])\n",
    "print(\"Random Forest Regressor R2:\")\n",
    "print(f\"Confirmed: {rfr_r2_confirmed}, Deaths: {rfr_r2_deaths}, Recovered: {rfr_r2_recovered}\")\n",
    "\n",
    "# score r2 gradient boosting\n",
    "gbr_r2_confirmed = r2_score(y_test['Confirmed'], gbr_y_pred[:, 0])\n",
    "gbr_r2_deaths = r2_score(y_test['Deaths'], gbr_y_pred[:, 1])\n",
    "gbr_r2_recovered = r2_score(y_test['Recovered'], gbr_y_pred[:, 2])\n",
    "print(\"Gradient Boosting Regressor R2:\")\n",
    "print(f\"Confirmed: {gbr_r2_confirmed}, Deaths: {gbr_r2_deaths}, Recovered: {gbr_r2_recovered}\")\n",
    "# score r2 linear regression\n",
    "lr_r2_confirmed = r2_score(y_test['Confirmed'], lr_y_pred[:, 0])\n",
    "lr_r2_deaths = r2_score(y_test['Deaths'], lr_y_pred[:, 1])\n",
    "lr_r2_recovered = r2_score(y_test['Recovered'], lr_y_pred[:, 2])\n",
    "print(\"Linear Regression R2:\")\n",
    "print(f\"Confirmed: {lr_r2_confirmed}, Deaths: {lr_r2_deaths}, Recovered: {lr_r2_recovered}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd637ef7-df83-4ded-bb7a-49c826d34b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/28 20:53:13 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "\u001b[31m2025/05/28 20:53:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Run '2a1392d6cc424b2792fb3446414b607d' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingConfigException\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/models/model.py:958\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 958\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfluent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_logged_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowException:\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;66;03m# We need to swallow all mlflow exceptions to maintain backwards compatibility with\u001b[39;00m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# older tracking servers. Only print out a warning for now.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/fluent.py:1607\u001b[0m, in \u001b[0;36m_record_logged_model\u001b[0;34m(mlflow_model, run_id)\u001b[0m\n\u001b[1;32m   1606\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m-> 1607\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_logged_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/client.py:3203\u001b[0m, in \u001b[0;36mMlflowClient._record_logged_model\u001b[0;34m(self, run_id, mlflow_model)\u001b[0m\n\u001b[1;32m   3197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Record logged model info with the tracking server.\u001b[39;00m\n\u001b[1;32m   3198\u001b[0m \n\u001b[1;32m   3199\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   3200\u001b[0m \u001b[38;5;124;03m    run_id: run_id under which the model has been logged.\u001b[39;00m\n\u001b[1;32m   3201\u001b[0m \u001b[38;5;124;03m    mlflow_model: Model info to be recorded.\u001b[39;00m\n\u001b[1;32m   3202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3203\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_logged_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:889\u001b[0m, in \u001b[0;36mTrackingServiceClient._record_logged_model\u001b[0;34m(self, run_id, mlflow_model)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlflow_model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be of type mlflow.models.Model but was \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(mlflow_model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m     )\n\u001b[0;32m--> 889\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_logged_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:1130\u001b[0m, in \u001b[0;36mFileStore.record_logged_model\u001b[0;34m(self, run_id, mlflow_model)\u001b[0m\n\u001b[1;32m   1129\u001b[0m _validate_run_id(run_id)\n\u001b[0;32m-> 1130\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m check_run_is_active(run_info)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:727\u001b[0m, in \u001b[0;36mFileStore._get_run_info\u001b[0;34m(self, run_uuid)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m, databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST\n\u001b[1;32m    726\u001b[0m     )\n\u001b[0;32m--> 727\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_info_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info\u001b[38;5;241m.\u001b[39mexperiment_id \u001b[38;5;241m!=\u001b[39m exp_id:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:736\u001b[0m, in \u001b[0;36mFileStore._get_run_info_from_dir\u001b[0;34m(self, run_dir)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_run_info_from_dir\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_dir):\n\u001b[0;32m--> 736\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mFileStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFileStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMETA_DATA_FILE_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_persisted_run_info_dict(meta)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:1373\u001b[0m, in \u001b[0;36mFileStore._read_yaml\u001b[0;34m(root, file_name, retries)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _read_helper(root, file_name, attempts_remaining \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattempts_remaining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:1366\u001b[0m, in \u001b[0;36mFileStore._read_yaml.<locals>._read_helper\u001b[0;34m(root, file_name, attempts_remaining)\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_helper\u001b[39m(root, file_name, attempts_remaining\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m-> 1366\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mread_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m attempts_remaining \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/utils/file_utils.py:310\u001b[0m, in \u001b[0;36mread_yaml\u001b[0;34m(root, file_name)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(file_path):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingConfigException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYaml file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mopen(file_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mENCODING) \u001b[38;5;28;01mas\u001b[39;00m yaml_file:\n",
      "\u001b[0;31mMissingConfigException\u001b[0m: Yaml file '/app/mlruns/961162627242522608/9a96ec4f73e14f38bb335edd124105a9/meta.yaml' does not exist.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMissingConfigException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m     generate_artifacts(rfr_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train, y_train,\n\u001b[1;32m    104\u001b[0m                       [rfr_rmse_confirmed, rfr_rmse_deaths, rfr_rmse_recovered],\n\u001b[1;32m    105\u001b[0m                       [rfr_r2_confirmed, rfr_r2_deaths, rfr_r2_recovered])\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfr_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# 6. Logging pour Gradient Boosting\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/sklearn/__init__.py:413\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03mLog a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03mcontaining the following flavors:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43msk_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/models/model.py:962\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, **kwargs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowException:\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;66;03m# We need to swallow all mlflow exceptions to maintain backwards compatibility with\u001b[39;00m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# older tracking servers. Only print out a warning for now.\u001b[39;00m\n\u001b[0;32m--> 962\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(_LOG_MODEL_METADATA_WARNING_TEMPLATE, \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_artifact_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    963\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/fluent.py:1966\u001b[0m, in \u001b[0;36mget_artifact_uri\u001b[0;34m(artifact_path)\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;124;03mGet the absolute URI of the specified artifact in the currently active run.\u001b[39;00m\n\u001b[1;32m   1915\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;124;03m    Artifact uri: file:///.../0/a46a80f1c9644bd8f4e5dd5553fffce/artifacts/features/features.txt\u001b[39;00m\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43martifact_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_artifact_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_or_start_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/artifact_utils.py:52\u001b[0m, in \u001b[0;36mget_artifact_uri\u001b[0;34m(run_id, artifact_path, tracking_uri)\u001b[0m\n\u001b[1;32m     51\u001b[0m store \u001b[38;5;241m=\u001b[39m _get_store(tracking_uri)\n\u001b[0;32m---> 52\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Maybe move this method to RunsArtifactRepository so the circular dependency is clearer.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:699\u001b[0m, in \u001b[0;36mFileStore.get_run\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    698\u001b[0m _validate_run_id(run_id)\n\u001b[0;32m--> 699\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:727\u001b[0m, in \u001b[0;36mFileStore._get_run_info\u001b[0;34m(self, run_uuid)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m, databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST\n\u001b[1;32m    726\u001b[0m     )\n\u001b[0;32m--> 727\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_info_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info\u001b[38;5;241m.\u001b[39mexperiment_id \u001b[38;5;241m!=\u001b[39m exp_id:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:736\u001b[0m, in \u001b[0;36mFileStore._get_run_info_from_dir\u001b[0;34m(self, run_dir)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_run_info_from_dir\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_dir):\n\u001b[0;32m--> 736\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mFileStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFileStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMETA_DATA_FILE_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_persisted_run_info_dict(meta)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:1373\u001b[0m, in \u001b[0;36mFileStore._read_yaml\u001b[0;34m(root, file_name, retries)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _read_helper(root, file_name, attempts_remaining \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattempts_remaining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:1366\u001b[0m, in \u001b[0;36mFileStore._read_yaml.<locals>._read_helper\u001b[0;34m(root, file_name, attempts_remaining)\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_helper\u001b[39m(root, file_name, attempts_remaining\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m-> 1366\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mread_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m attempts_remaining \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/utils/file_utils.py:310\u001b[0m, in \u001b[0;36mread_yaml\u001b[0;34m(root, file_name)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(file_path):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingConfigException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYaml file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mopen(file_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mENCODING) \u001b[38;5;28;01mas\u001b[39;00m yaml_file:\n",
      "\u001b[0;31mMissingConfigException\u001b[0m: Yaml file '/app/mlruns/961162627242522608/9a96ec4f73e14f38bb335edd124105a9/meta.yaml' does not exist.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMissingConfigException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m     generate_artifacts(rfr_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train, y_train,\n\u001b[1;32m    104\u001b[0m                       [rfr_rmse_confirmed, rfr_rmse_deaths, rfr_rmse_recovered],\n\u001b[1;32m    105\u001b[0m                       [rfr_r2_confirmed, rfr_r2_deaths, rfr_r2_recovered])\n\u001b[0;32m--> 106\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mlog_model(rfr_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# 6. Logging pour Gradient Boosting\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/fluent.py:229\u001b[0m, in \u001b[0;36mActiveRun.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    228\u001b[0m     status \u001b[38;5;241m=\u001b[39m RunStatus\u001b[38;5;241m.\u001b[39mFINISHED \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m RunStatus\u001b[38;5;241m.\u001b[39mFAILED\n\u001b[0;32m--> 229\u001b[0m     \u001b[43mend_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunStatus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/fluent.py:519\u001b[0m, in \u001b[0;36mend_run\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m    518\u001b[0m _last_active_run_id\u001b[38;5;241m.\u001b[39mset(last_active_run_id)\n\u001b[0;32m--> 519\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_terminated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_active_run_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_active_run_id \u001b[38;5;129;01min\u001b[39;00m run_id_to_system_metrics_monitor:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/client.py:3355\u001b[0m, in \u001b[0;36mMlflowClient.set_terminated\u001b[0;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[1;32m   3313\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set a run's status to terminated.\u001b[39;00m\n\u001b[1;32m   3314\u001b[0m \n\u001b[1;32m   3315\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3353\u001b[0m \n\u001b[1;32m   3354\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3355\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_terminated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:1035\u001b[0m, in \u001b[0;36mTrackingServiceClient.set_terminated\u001b[0;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_url(run_id)\n\u001b[0;32m-> 1035\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_run_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRunStatus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:631\u001b[0m, in \u001b[0;36mFileStore.update_run_info\u001b[0;34m(self, run_id, run_status, end_time, run_name)\u001b[0m\n\u001b[1;32m    630\u001b[0m _validate_run_id(run_id)\n\u001b[0;32m--> 631\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m check_run_is_active(run_info)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:727\u001b[0m, in \u001b[0;36mFileStore._get_run_info\u001b[0;34m(self, run_uuid)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m, databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST\n\u001b[1;32m    726\u001b[0m     )\n\u001b[0;32m--> 727\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_info_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info\u001b[38;5;241m.\u001b[39mexperiment_id \u001b[38;5;241m!=\u001b[39m exp_id:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:736\u001b[0m, in \u001b[0;36mFileStore._get_run_info_from_dir\u001b[0;34m(self, run_dir)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_run_info_from_dir\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_dir):\n\u001b[0;32m--> 736\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mFileStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFileStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMETA_DATA_FILE_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_persisted_run_info_dict(meta)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:1373\u001b[0m, in \u001b[0;36mFileStore._read_yaml\u001b[0;34m(root, file_name, retries)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _read_helper(root, file_name, attempts_remaining \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattempts_remaining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:1366\u001b[0m, in \u001b[0;36mFileStore._read_yaml.<locals>._read_helper\u001b[0;34m(root, file_name, attempts_remaining)\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_helper\u001b[39m(root, file_name, attempts_remaining\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m-> 1366\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mread_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m attempts_remaining \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/utils/file_utils.py:310\u001b[0m, in \u001b[0;36mread_yaml\u001b[0;34m(root, file_name)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(file_path):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingConfigException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYaml file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mopen(file_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mENCODING) \u001b[38;5;28;01mas\u001b[39;00m yaml_file:\n",
      "\u001b[0;31mMissingConfigException\u001b[0m: Yaml file '/app/mlruns/961162627242522608/9a96ec4f73e14f38bb335edd124105a9/meta.yaml' does not exist.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 136\u001b[0m\n\u001b[1;32m    125\u001b[0m         mlflow\u001b[38;5;241m.\u001b[39mlog_metrics({\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse_confirmed\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr_rmse_confirmed,\n\u001b[1;32m    127\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse_deaths\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr_rmse_deaths,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2_recovered\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr_r2_recovered\n\u001b[1;32m    132\u001b[0m         })\n\u001b[1;32m    133\u001b[0m         generate_artifacts(lr_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearRegression\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train, y_train,\n\u001b[1;32m    134\u001b[0m                           [lr_rmse_confirmed, lr_rmse_deaths, lr_rmse_recovered],\n\u001b[1;32m    135\u001b[0m                           [lr_r2_confirmed, lr_r2_deaths, lr_r2_recovered])\n\u001b[0;32m--> 136\u001b[0m         mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mlog_model(lr_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ MLflow logging completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/fluent.py:229\u001b[0m, in \u001b[0;36mActiveRun.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(r\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m active_run_stack):\n\u001b[1;32m    228\u001b[0m     status \u001b[38;5;241m=\u001b[39m RunStatus\u001b[38;5;241m.\u001b[39mFINISHED \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m RunStatus\u001b[38;5;241m.\u001b[39mFAILED\n\u001b[0;32m--> 229\u001b[0m     \u001b[43mend_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunStatus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/fluent.py:519\u001b[0m, in \u001b[0;36mend_run\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m    517\u001b[0m last_active_run_id \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[1;32m    518\u001b[0m _last_active_run_id\u001b[38;5;241m.\u001b[39mset(last_active_run_id)\n\u001b[0;32m--> 519\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_terminated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_active_run_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_active_run_id \u001b[38;5;129;01min\u001b[39;00m run_id_to_system_metrics_monitor:\n\u001b[1;32m    521\u001b[0m     system_metrics_monitor \u001b[38;5;241m=\u001b[39m run_id_to_system_metrics_monitor\u001b[38;5;241m.\u001b[39mpop(last_active_run_id)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/client.py:3355\u001b[0m, in \u001b[0;36mMlflowClient.set_terminated\u001b[0;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[1;32m   3310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_terminated\u001b[39m(\n\u001b[1;32m   3311\u001b[0m     \u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, status: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, end_time: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3312\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3313\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set a run's status to terminated.\u001b[39;00m\n\u001b[1;32m   3314\u001b[0m \n\u001b[1;32m   3315\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3353\u001b[0m \n\u001b[1;32m   3354\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_terminated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:1035\u001b[0m, in \u001b[0;36mTrackingServiceClient.set_terminated\u001b[0;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mshut_down_async_logging()\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_url(run_id)\n\u001b[0;32m-> 1035\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_run_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRunStatus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:631\u001b[0m, in \u001b[0;36mFileStore.update_run_info\u001b[0;34m(self, run_id, run_status, end_time, run_name)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate_run_info\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, run_status, end_time, run_name):\n\u001b[1;32m    630\u001b[0m     _validate_run_id(run_id)\n\u001b[0;32m--> 631\u001b[0m     run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m     check_run_is_active(run_info)\n\u001b[1;32m    633\u001b[0m     new_info \u001b[38;5;241m=\u001b[39m run_info\u001b[38;5;241m.\u001b[39m_copy_with_overrides(run_status, end_time, run_name\u001b[38;5;241m=\u001b[39mrun_name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:724\u001b[0m, in \u001b[0;36mFileStore._get_run_info\u001b[0;34m(self, run_uuid)\u001b[0m\n\u001b[1;32m    722\u001b[0m exp_id, run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_run_root(run_uuid)\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m, databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST\n\u001b[1;32m    726\u001b[0m     )\n\u001b[1;32m    727\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_run_info_from_dir(run_dir)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info\u001b[38;5;241m.\u001b[39mexperiment_id \u001b[38;5;241m!=\u001b[39m exp_id:\n",
      "\u001b[0;31mMlflowException\u001b[0m: Run '2a1392d6cc424b2792fb3446414b607d' not found"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# 1. Initialisation de l'expérience\n",
    "experiment_name = \"COVID-19_Predictions\"\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# 2. Fonction pour générer les artefacts\n",
    "def generate_artifacts(model, model_name, X_train, y_train, rmse_values, r2_values):\n",
    "    \"\"\"Génère et enregistre tous les artefacts pour un modèle\"\"\"\n",
    "    # Heatmap RMSE\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    sns.heatmap([rmse_values], annot=True, fmt=\".2f\", \n",
    "                xticklabels=['Confirmed', 'Deaths', 'Recovered'],\n",
    "                cmap=\"YlOrRd\")\n",
    "    plt.title(f\"RMSE - {model_name}\")\n",
    "    mlflow.log_figure(plt.gcf(), f\"rmse_heatmap.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Heatmap R2\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    sns.heatmap([r2_values], annot=True, fmt=\".2f\",\n",
    "                xticklabels=['Confirmed', 'Deaths', 'Recovered'],\n",
    "                cmap=\"YlGnBu\", vmin=-1, vmax=1)\n",
    "    plt.title(f\"R² - {model_name}\")\n",
    "    mlflow.log_figure(plt.gcf(), f\"r2_heatmap.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Learning Curve\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X_train, y_train, cv=3, scoring='r2')\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(train_sizes, np.mean(train_scores, axis=1), label=\"Train\")\n",
    "    plt.plot(train_sizes, np.mean(val_scores, axis=1), label=\"Validation\")\n",
    "    plt.title(f\"Learning Curve - {model_name}\")\n",
    "    mlflow.log_figure(plt.gcf(), f\"learning_curve.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Feature Importance (si applicable)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        sns.barplot(x=X_train.columns, y=model.feature_importances_)\n",
    "        plt.title(f\"Feature Importance - {model_name}\")\n",
    "        mlflow.log_figure(plt.gcf(), f\"feature_importance.png\")\n",
    "        plt.close()\n",
    "    elif model_name == \"GradientBoosting\":  # Cas spécifique pour MultiOutputRegressor\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 3))\n",
    "            sns.barplot(x=X_train.columns, y=model.estimators_[0].feature_importances_)\n",
    "            plt.title(f\"Feature Importance - {model_name} (First Target)\")\n",
    "            mlflow.log_figure(plt.gcf(), f\"feature_importance.png\")\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not generate feature importance for {model_name}: {str(e)}\")\n",
    "\n",
    "# 3. Fonction pour créer les heatmaps globales\n",
    "def create_global_heatmaps():\n",
    "    \"\"\"Crée et enregistre les heatmaps comparatives de tous les modèles\"\"\"\n",
    "    models = ['RandomForest', 'GradientBoosting', 'LinearRegression']\n",
    "    \n",
    "    # RMSE global\n",
    "    rmse_data = np.array([\n",
    "        [rfr_rmse_confirmed, rfr_rmse_deaths, rfr_rmse_recovered],\n",
    "        [gbr_rmse_confirmed, gbr_rmse_deaths, gbr_rmse_recovered],\n",
    "        [lr_rmse_confirmed, lr_rmse_deaths, lr_rmse_recovered]\n",
    "    ])\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(rmse_data, annot=True, fmt=\".2f\",\n",
    "                xticklabels=['Confirmed', 'Deaths', 'Recovered'],\n",
    "                yticklabels=models,\n",
    "                cmap=\"YlOrRd\")\n",
    "    plt.title(\"Comparaison globale des RMSE\")\n",
    "    mlflow.log_figure(plt.gcf(), \"global_rmse_comparison.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # R2 global\n",
    "    r2_data = np.array([\n",
    "        [rfr_r2_confirmed, rfr_r2_deaths, rfr_r2_recovered],\n",
    "        [gbr_r2_confirmed, gbr_r2_deaths, gbr_r2_recovered],\n",
    "        [lr_r2_confirmed, lr_r2_deaths, lr_r2_recovered]\n",
    "    ])\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(r2_data, annot=True, fmt=\".2f\",\n",
    "                xticklabels=['Confirmed', 'Deaths', 'Recovered'],\n",
    "                yticklabels=models,\n",
    "                cmap=\"YlGnBu\", vmin=-1, vmax=1)\n",
    "    plt.title(\"Comparaison globale des R²\")\n",
    "    mlflow.log_figure(plt.gcf(), \"global_r2_comparison.png\")\n",
    "    plt.close()\n",
    "\n",
    "# 4. Fonction pour logger un modèle\n",
    "def log_model_run(model, model_name, metrics, X_train, y_train):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_metrics(metrics)\n",
    "        generate_artifacts(model, model_name, X_train, y_train,\n",
    "                         [metrics['rmse_confirmed'], metrics['rmse_deaths'], metrics['rmse_recovered']],\n",
    "                         [metrics['r2_confirmed'], metrics['r2_deaths'], metrics['r2_recovered']])\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "# 5. Exécution principale\n",
    "# D'abord les visualisations globales dans un run dédié\n",
    "with mlflow.start_run(run_name=\"Global_Visualizations\"):\n",
    "    create_global_heatmaps()\n",
    "\n",
    "# Puis les runs pour chaque modèle\n",
    "models_data = {\n",
    "    \"RandomForest\": {\n",
    "        \"model\": rfr_model,\n",
    "        \"metrics\": {\n",
    "            \"rmse_confirmed\": rfr_rmse_confirmed,\n",
    "            \"rmse_deaths\": rfr_rmse_deaths,\n",
    "            \"rmse_recovered\": rfr_rmse_recovered,\n",
    "            \"r2_confirmed\": rfr_r2_confirmed,\n",
    "            \"r2_deaths\": rfr_r2_deaths,\n",
    "            \"r2_recovered\": rfr_r2_recovered\n",
    "        }\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": gbr_model,\n",
    "        \"metrics\": {\n",
    "            \"rmse_confirmed\": gbr_rmse_confirmed,\n",
    "            \"rmse_deaths\": gbr_rmse_deaths,\n",
    "            \"rmse_recovered\": gbr_rmse_recovered,\n",
    "            \"r2_confirmed\": gbr_r2_confirmed,\n",
    "            \"r2_deaths\": gbr_r2_deaths,\n",
    "            \"r2_recovered\": gbr_r2_recovered\n",
    "        }\n",
    "    },\n",
    "    \"LinearRegression\": {\n",
    "        \"model\": lr_model,\n",
    "        \"metrics\": {\n",
    "            \"rmse_confirmed\": lr_rmse_confirmed,\n",
    "            \"rmse_deaths\": lr_rmse_deaths,\n",
    "            \"rmse_recovered\": lr_rmse_recovered,\n",
    "            \"r2_confirmed\": lr_r2_confirmed,\n",
    "            \"r2_deaths\": lr_r2_deaths,\n",
    "            \"r2_recovered\": lr_r2_recovered\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "for model_name, data in models_data.items():\n",
    "    log_model_run(data[\"model\"], model_name, data[\"metrics\"], X_train, y_train)\n",
    "\n",
    "print(\"✅ MLflow logging completed!\")\n",
    "print(f\"Pour visualiser les résultats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a66723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le pickle pour le modèle Random Forest\n",
    "import pickle\n",
    "with open('../api/model.pkl', 'wb') as f:\n",
    "    pickle.dump(rfr_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
